"use strict";(self.webpackChunkjellyfish_docs=self.webpackChunkjellyfish_docs||[]).push([[5424],{94256:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>n,metadata:()=>a,toc:()=>c});var i=s(17624),r=s(4552);const n={},o="Metrics Design",a={id:"for_developers/metrics_design",title:"Metrics Design",description:"Currently, jellyfish exposed a few metrics, which included a label room_id.",source:"@site/docs/for_developers/metrics_design.md",sourceDirName:"for_developers",slug:"/for_developers/metrics_design",permalink:"/jellyfish-docs/next/for_developers/metrics_design",draft:!1,unlisted:!1,editUrl:"https://github.com/jellyfish-dev/jellyfish-docs/docs/for_developers/metrics_design.md",tags:[],version:"current",frontMatter:{},sidebar:"mainSidebar",previous:{title:"Design Docs",permalink:"/jellyfish-docs/next/for_developers/design_docs"},next:{title:"API Reference",permalink:"/jellyfish-docs/next/for_developers/api_reference"}},l={},c=[{value:"Additional Resources:",id:"additional-resources",level:4}];function d(e){const t={a:"a",code:"code",h1:"h1",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.M)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"metrics-design",children:"Metrics Design"}),"\n",(0,i.jsx)(t.p,{children:"Currently, jellyfish exposed a few metrics, which included a label room_id.\nSome could be worried about the cardinality of this type of metric.\nTo answer these worries, we have to deepen our knowledge about Prometheus metrics.\nEach unique labelset creates a separate time series.\nEach additional time series has RAM, CPU, disk, and network costs.\nThis cost is usually negligible, but when we talk about hundreds of servers and metrics, it can add up quickly.\nBut the question is, how quickly will this add up?"}),"\n",(0,i.jsx)(t.p,{children:"At the moment (16.11.2023), Prometheus can handle around ten million time series.\nPrometheus maintainers suggest that when analyzing the capacity of Prometheus, we should think about a cluster where one Prometheus instance monitors around 1000 servers.\nDefault retention in Prometheus is 15 days, meaning time series older than 15 days are removed.\nBased on this assumption, we can approximate how many rooms per hour on each of 1000 jellyfish for 15 days straight must be created to reach Prometheus limits."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"room_per_hour_on_jellyfish =\n= total_time_series_limit / number_of_jellyfishes / prometheus_retention_in_days / hours_in_day = \n= 10_000_000 / 1_000 / 15 / 24 = 27\n"})}),"\n",(0,i.jsx)(t.p,{children:"This limit is pretty high and, in most use cases, shouldn't be a problem.\nBut to be cautious, we will add this label only to metrics where that is required, and we will try to minimize the amount of metrics where that is used."}),"\n",(0,i.jsx)(t.p,{children:"If this label is a problem for you, there are a few solutions:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["We are thinking about adding a possibility to configurable disable metrics that use the label ",(0,i.jsx)(t.code,{children:"room_id"}),", but it is not in our current roadmap"]}),"\n",(0,i.jsx)(t.li,{children:"You can define in Prometheus that at the scrape time, some labels will be dropped from metrics. (Remember that label dropping should be done cautiously as it could lead to the dropping of some data or aggregation)."}),"\n",(0,i.jsx)(t.li,{children:"Similarly to previous in Prometheus, at the scrape time, you can define to drop some specific metric."}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["To get more information about relabeling, metrics or label dropping we suggest to read ",(0,i.jsx)(t.a,{href:"https://grafana.com/docs/grafana-cloud/cost-management-and-billing/reduce-costs/metrics-costs/client-side-filtering/",children:"grafana tutorial"}),"."]}),"\n",(0,i.jsx)(t.h4,{id:"additional-resources",children:"Additional Resources:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://prometheus.io/docs/practices/instrumentation/#use-labels",children:"https://prometheus.io/docs/practices/instrumentation/#use-labels"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://stackoverflow.com/a/69167162",children:"https://stackoverflow.com/a/69167162"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://newrelic.com/blog/how-to-relic/manage-prometheus-cardinality",children:"https://newrelic.com/blog/how-to-relic/manage-prometheus-cardinality"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://grafana.com/blog/2022/10/20/how-to-manage-high-cardinality-metrics-in-prometheus-and-kubernetes/",children:"https://grafana.com/blog/2022/10/20/how-to-manage-high-cardinality-metrics-in-prometheus-and-kubernetes/"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/",children:"https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/"})}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.M)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},4552:(e,t,s)=>{s.d(t,{I:()=>a,M:()=>o});var i=s(11504);const r={},n=i.createContext(r);function o(e){const t=i.useContext(n);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(n.Provider,{value:t},e.children)}}}]);