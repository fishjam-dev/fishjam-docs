---
title: React Native
---

import { ImageWrapper } from "./ImageWrapper";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import FishjamArchitecture from "./common/_fishjam-architecture.mdx";
import StartingFishjamBackend from "./common/_starting-fishjam-media-server.mdx";
import StartingFishjamDashboard from "./common/_starting-dashboard.mdx";

# React Native Minimal Working Example

:::note

This guide expects that you have read [`Basic Concepts`](docs/introduction/basic_concepts.md) and [`Example Scenarios`](docs/introduction/example_scenarios.md)


This tutorial is compatible with react-native-client-sdk version 0.1.6
:::

## What you'll learn

This tutorial will guide you through creating your first React Native / Expo
project which uses Fishjam client. By the end of the tutorial, you'll have a
working application that connects to an instance of [Fishjam Server](https://github.com/fishjam-dev/fishjam) using WebRTC,
streaming and receiving multimedia.

<ImageWrapper url={"/img/tutorials/rn_full_app.gif"} />

## What do you need

- a little bit of experience in creating apps with React Native and/or Expo -
refer to the [React Native
Guide](https://reactnative.dev/docs/getting-started) or [Expo
Guide](https://docs.expo.dev/) to learn more

## Fishjam architecture

<FishjamArchitecture />

## Setup

### Start the Fishjam Dashboard

<StartingFishjamBackend />

### Start the dashboard web front-end

<StartingFishjamDashboard />

### Create React Native / Expo project

:::info

If you want to skip creating and setuping app clone this [repo](https://github.com/karkakol/react-native-fishjam-example-begin-0.1.6). Then continue from this [step](#screens).

If you want ready to use app just clone and run this [repo](https://github.com/karkakol/react-native-fishjam-example-end-0.1.6). Remember to change your [server url](https://github.com/karkakol/react-native-fishjam-example-end-0.1.6/blob/5ef7d7ac6146d3d631598c2f6168d5dc591a1377/screens/Connect.tsx#L22).
:::

Firstly create a brand new project and change directory.

<Tabs>
    <TabItem value="react-native" label="React Native">

        ```bash
        npx react-native@latest init ReactNativeFishjamExample && cd ReactNativeFishjamExample
        ```

    </TabItem>
    <TabItem value="expo-bare" label="Expo Bare workflow">

        ```bash
        npx react-native init ReactNativeFishjamExample --template react-native-template-typescript && cd ReactNativeFishjamExample
        ```

    </TabItem>
</Tabs>

### Add dependencies

:::note

Please make sure to install or update `expo` to version `^50.0.0`

:::


You have two options here. You can follow configuration instructions for
React Native (Expo Bare workflow is a React Native project after all) or if
you're using `expo prebuild` command to set up native code you can add our Expo
plugin.

Just add it to `app.json`:

```json title:app.json
{
  "expo": {
    "name": "example",
    //...
    "plugins": ["@fishjam-dev/react-native-membrane-webrtc"]
  }
}
```

<Tabs>
    <TabItem value="react-native" label="React Native">
        In order for this module to work, you'll need to also add `expo` package. The
        package introduces a small footprint, but is necessary as the Fishjam client
        package is built as Expo module.
        <Tabs>
            <TabItem value="npm" label="npm">
                ```bash npm2yarn
                npx install-expo-modules@latest
                npm install @fishjam-dev/react-native-client-sdk
                ```
            </TabItem>
            <TabItem value="Yarn" label="Yarn">
                ```bash npm2yarn
                npx install-expo-modules@latest
                yarn add @fishjam-dev/react-native-client-sdk
                ```
            </TabItem>
        </Tabs>
    </TabItem>

    <TabItem value="expo-bare" label="Expo Bare workflow">

        ```bash
        npx install-expo-modules@latest
        npx expo install @fishjam-dev/react-native-client-sdk
        ```

    </TabItem>

</Tabs>

:::tip
Run `pod install` in the /ios directory to install the new pods
:::

### Native permissions configuration

In order to let the application access microphone and camera, you'll need to add some native configuration:

You need to at least set up camera permissions.

On Android add to your `AndroidManifest.xml`:

```xml title=AndroidManifest.xml
  <uses-permission android:name="android.permission.CAMERA"/>
```

For audio you'll need the `RECORD_AUDIO` permission:

```xml title=AndroidManifest.xml
  <uses-permission android:name="android.permission.RECORD_AUDIO"/>
```

On iOS you must set `NSCameraUsageDescription` in `Info.plist` file. This value is a description that is shown when iOS asks user
for camera permission.

```xml title=ios/fishjam-dashboard/Info.plist
<key>NSCameraUsageDescription</key>
<string> üôè üé• </string>
```

Similarly, for audio there is `NSMicrophoneUsageDescription`.

```xml title=ios/fishjam-dashboard/Info.plist
<key>NSMicrophoneUsageDescription</key>
<string> üôè üé§ </string>
```

We also suggest setting background mode to `audio` so that the app doesn't
disconnect when it's in the background:

```xml title=ios/fishjam-dashboard/Info.plist
<key>UIBackgroundModes</key>
<array>
  <string>audio</string>
</array>
```

Screencast requires additional configuration, you can find the details [here](https://github.com/fishjam-dev/react-native-client-sdk#ios). To keep this tutorial simple, we will skip this step.


### Add source components

For your convenience, we've prepared some files with nice-looking components
useful for following this tutorial. Feel free to use standard React Native components or your own components though!

In order to use those files, you need to unzip them and place both folders in your project directory (the one where your `package.json` is located).

[Download resources](/react_native/resources.zip)

Don't forget to install additional packages which are mandatory to make our components work properly.

```bash
npx expo install @expo/vector-icons expo-camera@14.0.x expo-font @expo-google-fonts/noto-sans @react-navigation/native-stack
```

**_You'll also need to setup and install [Reanimated library (3.3.0)](https://docs.swmansion.com/react-native-reanimated/docs/fundamentals/getting-started), [React Navigation (6.1.7)](https://reactnavigation.org/docs/getting-started) for bare react native project. Also setup [Expo Camera (14.0.6)](https://github.com/expo/expo/tree/sdk-50/packages/expo-camera)._**

:::tip
Run `pod install` in the /ios directory to install the new pods
:::

## Screens

For managing screens we will use React Navigation library, but feel free to pick whatever suits you.
Our app will consist of two screens:
- `ConnectScreen` will allow a user to type in, paste or scan a peer token and connect to the room
- `RoomScreen` will show room participants with their video tracks

```tsx title="/App.tsx"
import React from "react";
import { NavigationContainer } from "@react-navigation/native";
import { createNativeStackNavigator } from "@react-navigation/native-stack";
import ConnectScreen from "./screens/Connect";
import RoomScreen from "./screens/Room";

const Stack = createNativeStackNavigator();

function App(): React.JSX.Element {
  return (
    <NavigationContainer>
      <Stack.Navigator>
        <Stack.Screen name="Connect" component={ConnectScreen} />
        <Stack.Screen name="Room" component={RoomScreen} />
      </Stack.Navigator>
    </NavigationContainer>
  );
}

export default App;
```

## ConnectScreen

The UI of the `ConnectScreen` consists of a simple text input and a few buttons.
The flow for this screen is simple:
the user either copies the peer token from the
dashboard or scans it with a QR code scanner and presses Connect button.
The QR code scanner is provided by our components library and it's completely optional,
just for convenience.

The code for the UI looks like this:

```tsx title="/screens/Connect.tsx"
import React, { useState } from "react";
import { View, StyleSheet } from "react-native";
import { NavigationProp } from "@react-navigation/native";
import QRCodeScanner from '../components/QRCodeScanner';
import Button from '../components/Button';
import TextInput from '../components/TextInput';

interface ConnectScreenProps {
  navigation: NavigationProp<any>;
}

function ConnectScreen({ navigation }: ConnectScreenProps): React.JSX.Element {
  const [peerToken, setPeerToken] = useState<string>("");

  return (
    <View style={styles.container}>
      <TextInput
        placeholder="Enter peer token"
        value={peerToken}
        onChangeText={setPeerToken}
      />
      <Button
        onPress={() => {
          /* to be filled */
        }}
        title="Connect"
        disabled={!peerToken}
      />
      <QRCodeScanner onCodeScanned={setPeerToken} />
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: "center",
    backgroundColor: "#BFE7F8",
    padding: 24,
    rowGap: 24,
  },
});

export default ConnectScreen;
```

### Connecting to the server

Once the UI is ready, let's implement the logic responsible for connecting to the server.

Firstly wrap your app with `JelyfishContextProvider`:

```tsx title="/App.tsx"
import React from "react";
// highlight-next-line
import { FishjamContextProvider } from "@fishjam-dev/react-native-client-sdk";
import { NavigationContainer } from "@react-navigation/native";
import { createNativeStackNavigator } from "@react-navigation/native-stack";
import ConnectScreen from "./screens/Connect";
import RoomScreen from "./screens/Room";

const Stack = createNativeStackNavigator();

function App(): React.JSX.Element {
  return (
    // highlight-next-line
    <FishjamContextProvider>
      <NavigationContainer>
        <Stack.Navigator>
          <Stack.Screen name="Connect" component={ConnectScreen} />
          <Stack.Screen name="Room" component={RoomScreen} />
        </Stack.Navigator>
      </NavigationContainer>
      // highlight-next-line
    </FishjamContextProvider>
  );
}

export default App;
```

Then in the `ConnectScreen` use the `useFishjamClient` hook to connect to the
server. Simply call the `connect` method with your Fishjam server URL and the
peer token. The `connect` function establishes a connection with the Fishjam server
via web socket and authenticates the peer.

```tsx title="/screens/Connect.tsx"
// highlight-next-line
import { useFishjamClient } from "@fishjam-dev/react-native-client-sdk";
import { NavigationProp } from "@react-navigation/native";

interface ConnectScreenProps {
  navigation: NavigationProp<any>;
}

// This is the address of the Fishjam backend. Change the local IP to yours. We
// strongly recommend setting this as an environment variable, we hardcoded it here
// for simplicity.
// If you use secure connection with your Fishjam Media Server change ws to wss in this variable.
// highlight-next-line
const FISHJAM_URL = "ws://X.X.X.X:5002/socket/peer/websocket";

function ConnectScreen({ navigation }: ConnectScreenProps): React.JSX.Element {
  const [peerToken, setPeerToken] = useState<string>("");

  // highlight-next-line
  const { connect } = useFishjamClient();

  // highlight-start
  const connectToRoom = async () => {
    try {
      await connect(FISHJAM_URL, peerToken.trim());
    } catch (e) {
      console.log("Error while connecting", e);
    }
  };
  // highlight-end
  return (
    <View style={styles.container}>
      <TextInput
        placeholder="Enter peer token"
        value={peerToken}
        onChangeText={setPeerToken}
      />
      // highlight-next-line
      <Button onPress={connectToRoom} title="Connect" disabled={!peerToken} />
      <QRCodeScanner onCodeScanned={setPeerToken} />
    </View>
  );
}

// ...
```

### Camera permissions (Android only)

To start the camera we need to ask the user for permission first. We'll use a
standard React Native module for this:

```tsx title="/screens/Connect.tsx"

import {
  View,
  StyleSheet,
//highlight-start
  type Permission,
  PermissionsAndroid,
  Platform,
//highlight-end
} from "react-native";



// ...

function ConnectScreen({ navigation }: ConnectScreenProps): React.JSX.Element {
  // ...

  // highlight-start
  const grantedCameraPermissions = async () => {
    if (Platform.OS === "ios") return true;
    const granted = await PermissionsAndroid.request(
      PermissionsAndroid.PERMISSIONS.CAMERA as Permission
    );
    if (granted !== PermissionsAndroid.RESULTS.GRANTED) {
      console.error("Camera permission denied");
      return false;
    }
    return true;
  };
  // highlight-end

  const connectToRoom = async () => {
    try {
      await connect(FISHJAM_URL, peerToken.trim());

      // highlight-start
      if (!(await grantedCameraPermissions())) {
        return;
      }
      // highlight-end
    } catch (e) {
      console.log("Error while connecting", e);
    }
  };

  // ...
}

// ...
```

### Starting the camera

Fishjam Client provides a handy hook for managing the camera: `useCamera`.
Not only it can start a camera but also toggle it, manage its state, simulcast and bandwidth settings, and switch between multiple sources.
Also when starting the camera you can provide multiple different settings such as
resolution, quality, and metadata.
In this example though we'll simply turn it
on to stream the camera to the dashboard with default settings

```tsx title="/screens/Connect.tsx"
import {
  useFishjamClient,
  // highlight-next-line
  useCamera,
} from "@fishjam-dev/react-native-client-sdk";

// ...

function ConnectScreen({ navigation }: ConnectScreenProps): React.JSX.Element {
  // ...

  // highlight-next-line
  const { startCamera } = useCamera();

  const connectToRoom = async () => {
    try {
      await connect(FISHJAM_URL, peerToken.trim());

      if (!(await grantedCameraPermissions())) {
        return;
      }

      // highlight-next-line
      await startCamera();
    } catch (e) {
      console.log("Error while connecting", e);
    }
  };

  // ...
}

// ...
```

### Joining the room

The last step of connecting to the room would be actually joining it so
that your camera track is visible to the other users.
To do this simply use the `join` function
from the `useFishjamClient` hook.

You can also provide some user metadata when joining.
Metadata can be anything and is forwarded to the other participants as is.
In our case, we pass a username.

After joining the room we navigate to the next screen: Room screen.

```tsx title="/screens/Connect.tsx"
// ...

function ConnectScreen({ navigation }: ConnectScreenProps): React.JSX.Element {
  // highlight-next-line
  const { connect, join } = useFishjamClient();

  const connectToRoom = async () => {
    try {
      await connect(FISHJAM_URL, peerToken.trim());

      if (!(await grantedCameraPermissions())) {
        return;
      }

      await startCamera();

      // highlight-next-line
      await join({ name: "Mobile RN Client" });
      // highlight-next-line
      navigation.navigate("Room");
    } catch (e) {
      console.log("Error while connecting", e);
    }
  };

  // ...
}

// ...
```


## RoomScreen

### Displaying video tracks

The `Room` screen has a couple of responsibilities:

- it displays your own video.
Note that it's taken directly from your camera i.e. we don't send it to the JF and get it back so other participants might see you a little bit differently
- it presents current room state so participants list, their video tiles, etc.
- it allows you to leave a meeting

To get information about all participants (also the local one) in the room use
`usePeers()` hook from Fishjam Client. The hook returns all the participants
with their ids, tracks and metadata. When a new participant joins or any
participant leaves or anything else changes, the hook updates with the new
information.

To display video tracks Fishjam Client comes with a dedicated component for
displaying a video track: `<VideoRenderer>`. It takes a track id as a prop (it
may be a local or remote track) and, as any other `<View>` in react, a style.
style property gives a [lot of possibilities](https://reactnative.dev/docs/stylesheet). You can even animate your track!

So, let's display all the participants in the simplest way possible:

```tsx title="/screens/Room.tsx"
import React from "react";
import { View, StyleSheet } from "react-native";
import { NavigationProp } from "@react-navigation/native";
// highlight-start
import {
  usePeers,
  VideoRendererView,
} from "@fishjam-dev/react-native-client-sdk";
// highlight-end

interface RoomScreenProps {
  navigation: NavigationProp<any>;
}

function RoomScreen({ navigation }: RoomScreenProps): React.JSX.Element {
  // highlight-next-line
  const peers = usePeers();

  return (
    <View style={styles.container}>
      <View style={styles.videoContainer}>
        // highlight-start
        {peers.map((peer) =>
          peer.tracks[0] ? (
            <VideoRendererView
              trackId={peer.tracks[0].id}
              style={styles.video}
            />
          ) : null
        )}
        // highlight-end
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    alignItems: "center",
    justifyContent: "space-between",
    backgroundColor: "#F1FAFE",
    padding: 24,
  },
  videoContainer: {
    flexDirection: "row",
    gap: 8,
    flexWrap: "wrap",
  },
  video: { width: 200, height: 200 },
});

export default RoomScreen;
```

### First test


Now the app is ready for the first test.

This video shows how to connect to Fishjam dashboard, create room and peers.

<ImageWrapper url={"/react_native/dashboard_connect_to_media_server.gif"} />

This image shows how you can obtain peer token.

<ImageWrapper url={"/react_native/dashboard_peer_token.png"} />

For physical devices, it would be easier to scan a QR code to input the peer token into the app. For virtual devices, it is more convenient to copy the token to the clipboard and then paste it.

:::note

Don't connect with the same peer simultaneously from dashboard and mobile app.

:::

:::note

Ios simulator does not support camera, but it will display remote tracks. It is strongly recommended to use physical device or android emulator where you can see your camera preview.

:::

:::note
Due to react-native hot-reload feature sometimes following error may occur in console logs:

`Error while connecting [Error: WebSocket was closed: 1000 peer already connected]`.

To fix it just kill your app and run it again. Later we will add disconnect button and it will solve this issue.
:::

Before launching your app, start Metro:

<Tabs>
    <TabItem value="npm" label="npm">

        ```bash
        npm start
        ```

    </TabItem>
    <TabItem value="Yarn" label="Yarn">

        ```bash
        yarn start
        ```

    </TabItem>
</Tabs>

To launch your app, you can use the following command:



<Tabs>
    <TabItem value="npm" label="npm">

        <Tabs>
            <TabItem value="ios" label="ios">

                ```bash
                cd ios && pod install && cd .. && npm run ios
                ```

            </TabItem>
            <TabItem value="android" label="android">

                ```bash
                npm run android
                ```

            </TabItem>
        </Tabs>

    </TabItem>
    <TabItem value="Yarn" label="Yarn">

        <Tabs>
            <TabItem value="ios" label="ios">

                ```bash
                cd ios && pod install && cd .. && yarn ios
                ```

            </TabItem>
            <TabItem value="android" label="android">

                ```bash
                yarn android
                ```

            </TabItem>
        </Tabs>

    </TabItem>
</Tabs>

If everything went well you should see
a preview from your camera in app.

<ImageWrapper url={"/react_native/room_screen_with_camera_only.gif"} height={720}/>

Now onto the second part:
displaying the streams from other participants.

This gif shows how to add a fake peer that shares a video track in the dashboard (remember to check the `Attach metadata` checkbox):

<ImageWrapper url={"/react_native/add_track_in_fishjam.gif"} />

It should show up in the Room screen automatically:

<ImageWrapper url={"/react_native/unstyled_track_joining_from_dashboard.gif"} height={720} />

Let's utilize the provided components to implement basic styling and layout for organizing video tracks in a visually appealing grid.

```tsx title="/screens/Room.tsx"
// highlight-start
import React, {useMemo} from 'react';
import VideosGrid from '../components/VideosGrid.tsx';
// highlight-end

// ...

function RoomScreen({ navigation }: RoomScreenProps): React.JSX.Element {
  const peers = usePeers();
  // highlight-start
  const tracks = useMemo(() =>
    peers.flatMap(peer =>
      peer.tracks.filter(
        t => t.metadata.type !== 'audio' && (t.metadata.active ?? true),
      ),
  ), [peers]);
  // highlight-end

  return (
    <View style={styles.container}>
      // highlight-start
      <VideosGrid
        tracks={tracks}
      />
      // highlight-end
    </View>
  );
}
```

### Gracefully leaving the room

To leave a room we'll add a button for the user. When the user clicks it, we
gracefully leave the room, close the server connection and go back to the
`Connectscreen`.

For leaving the room and closing the server connection you can use the `cleanUp` method from the `useFishjamClient()` hook.

```tsx title="/screens/Room.tsx"
// ...

import {
  usePeers,
  VideoRendererView,
  // highlight-next-line
  useFishjamClient,
} from "@fishjam-dev/react-native-client-sdk";
// highlight-next-line
import InCallButton from '../components/InCallButton.tsx';

// ...

function RoomScreen({ navigation }: RoomScreenProps): React.JSX.Element {
  const peers = usePeers();
  // highlight-start
  const { cleanUp } = useFishjamClient();

  const onDisconnectPress = () => {
    cleanUp();
    navigation.goBack();
  };
  // highlight-end

  return (
    <View style={styles.container}>
      <VideosGrid
        tracks={tracks}
      />
      // highlight-start
      <InCallButton
        type="disconnect"
        iconName="phone-hangup"
        onPress={onDisconnectPress}
      />
      // highlight-end
    </View>
  );
}

// ...
```

Now your app should look like this:

<ImageWrapper url={"/react_native/track_joining_from_dashboard.gif"} height={720}/>

## Summary

Congrats on finishing your first Fishjam mobile application! In this tutorial,
you've learned how to make a basic Fishjam client application that streams and
receives video tracks with WebRTC technology.

But this was just the beginning. Fishjam Client supports much more than just
streaming camera: it can also stream audio, screencast your device's screen,
configure your camera and audio devices, detect voice activity, control
simulcast, bandwidth and encoding settings, show camera preview, display WebRTC
stats and more to come. Check out our other tutorials to learn about those
features.

You can also take a look at our fully featured [Videoroom Demo
example](https://github.com/fishjam-dev/react-native-membrane-webrtc/tree/master/example):

![Videoroom Demo](/img/tutorials/videoroom.gif)
